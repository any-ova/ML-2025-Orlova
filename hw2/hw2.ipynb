{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D0E_KjL3eBM",
        "outputId": "345f7a77-af25-4ec9-cf4c-6076b968c7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss: 1.446, Test Loss: 0.542, Train Acc: 0.536, Test Acc: 0.854\n",
            "Epoch 1: Train Loss: 0.418, Test Loss: 0.323, Train Acc: 0.886, Test Acc: 0.910\n",
            "Epoch 2: Train Loss: 0.281, Test Loss: 0.240, Train Acc: 0.922, Test Acc: 0.933\n",
            "Epoch 3: Train Loss: 0.213, Test Loss: 0.189, Train Acc: 0.941, Test Acc: 0.948\n",
            "Epoch 4: Train Loss: 0.169, Test Loss: 0.157, Train Acc: 0.953, Test Acc: 0.955\n",
            "Epoch 5: Train Loss: 0.140, Test Loss: 0.133, Train Acc: 0.961, Test Acc: 0.962\n",
            "Epoch 6: Train Loss: 0.119, Test Loss: 0.119, Train Acc: 0.967, Test Acc: 0.966\n",
            "Epoch 7: Train Loss: 0.104, Test Loss: 0.115, Train Acc: 0.972, Test Acc: 0.966\n",
            "Epoch 8: Train Loss: 0.091, Test Loss: 0.104, Train Acc: 0.975, Test Acc: 0.969\n",
            "Epoch 9: Train Loss: 0.081, Test Loss: 0.100, Train Acc: 0.978, Test Acc: 0.971\n",
            "Epoch 10: Train Loss: 0.073, Test Loss: 0.094, Train Acc: 0.980, Test Acc: 0.972\n",
            "Epoch 11: Train Loss: 0.065, Test Loss: 0.090, Train Acc: 0.982, Test Acc: 0.972\n",
            "Epoch 12: Train Loss: 0.059, Test Loss: 0.089, Train Acc: 0.985, Test Acc: 0.973\n",
            "Epoch 13: Train Loss: 0.053, Test Loss: 0.085, Train Acc: 0.986, Test Acc: 0.975\n",
            "Epoch 14: Train Loss: 0.049, Test Loss: 0.085, Train Acc: 0.988, Test Acc: 0.974\n",
            "Epoch 15: Train Loss: 0.044, Test Loss: 0.083, Train Acc: 0.989, Test Acc: 0.974\n",
            "Epoch 16: Train Loss: 0.040, Test Loss: 0.082, Train Acc: 0.991, Test Acc: 0.975\n",
            "Epoch 17: Train Loss: 0.036, Test Loss: 0.081, Train Acc: 0.992, Test Acc: 0.975\n",
            "Epoch 18: Train Loss: 0.033, Test Loss: 0.081, Train Acc: 0.993, Test Acc: 0.976\n",
            "Epoch 19: Train Loss: 0.030, Test Loss: 0.081, Train Acc: 0.994, Test Acc: 0.975\n",
            "\n",
            "Final Results (Tanh, no augmentations):\n",
            "Train Accuracy: 0.994, Test Accuracy: 0.975\n",
            "Train Loss: 0.030, Test Loss: 0.081\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import sys\n",
        "\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "\n",
        "class Linear:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        '''\n",
        "        Creates weights and biases for linear layer.\n",
        "        Dimention of inputs is *input_size*, of output: *output_size*.\n",
        "        '''\n",
        "        self.W = np.random.randn(input_size, output_size)*0.01\n",
        "        self.b = np.zeros(output_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "        '''\n",
        "        Passes objects through this layer.\n",
        "        X is np.array of size (N, input_size).\n",
        "        Returns output of size (N, output_size).\n",
        "        Hint: You may need to store X for backward pass\n",
        "        '''\n",
        "        self.X = X\n",
        "        return X.dot(self.W)+self.b\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        '''\n",
        "        1. Compute dLdw and dLdx.\n",
        "        2. Store dLdw for step() call\n",
        "        3. Return dLdx\n",
        "        '''\n",
        "        self.dLdW = self.X.T.dot(dLdy)\n",
        "        self.dLdb = dLdy.sum(0)\n",
        "        self.dLdx = dLdy.dot(self.W.T)\n",
        "        return self.dLdx\n",
        "\n",
        "    def step(self, learning_rate):\n",
        "        '''\n",
        "        1. Apply gradient dLdw to network:\n",
        "        w <- w - learning_rate*dLdw\n",
        "        '''\n",
        "        self.W = self.W - learning_rate * self.dLdW\n",
        "        self.b = self.b - learning_rate * self.dLdb\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        '''\n",
        "        Passes objects through this layer.\n",
        "        X is np.array of size (N, d)\n",
        "        '''\n",
        "        self.s = 1./(1+np.exp(-X))\n",
        "        return self.s\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        '''\n",
        "        1. Compute dLdx.\n",
        "        2. Return dLdx\n",
        "        '''\n",
        "        return self.s*(1-self.s)*dLdy\n",
        "\n",
        "    def step(self, learning_rate):\n",
        "        pass\n",
        "\n",
        "class NLLLoss:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, X, y):\n",
        "        '''\n",
        "        Passes objects through this layer.\n",
        "        X is np.array of size (N, C), where C is the number of classes\n",
        "        y is np.array of size (N), contains correct labels\n",
        "        '''\n",
        "        self.p = np.exp(X)\n",
        "        self.p /= self.p.sum(1, keepdims=True)\n",
        "        self.y = np.zeros((X.shape[0], X.shape[1]))\n",
        "        self.y[np.arange(X.shape[0]), y] = 1\n",
        "        return -(np.log(self.p)*self.y).sum(1).mean(0)\n",
        "\n",
        "    def backward(self):\n",
        "        '''\n",
        "        Note that here dLdy = 1 since L = y\n",
        "        1. Compute dLdx\n",
        "        2. Return dLdx\n",
        "        '''\n",
        "        return (self.p - self.y) / self.y.shape[0]\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, modules):\n",
        "        '''\n",
        "        Constructs network with *modules* as its layers\n",
        "        '''\n",
        "        self.modules = modules\n",
        "\n",
        "    def forward(self, X):\n",
        "        y = X\n",
        "        for i in range(len(self.modules)):\n",
        "            y = self.modules[i].forward(y)\n",
        "        return y\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        '''\n",
        "        dLdy here is a gradient from loss function\n",
        "        '''\n",
        "        for i in range(len(self.modules))[::-1]:\n",
        "            dLdy = self.modules[i].backward(dLdy)\n",
        "\n",
        "    def step(self, learning_rate):\n",
        "        for i in range(len(self.modules)):\n",
        "            self.modules[i].step(learning_rate)\n",
        "\n",
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        '''\n",
        "        Passes objects through this layer.\n",
        "        X is np.array of size (N, d)\n",
        "        '''\n",
        "        self.X = X\n",
        "        return np.maximum(X, 0)\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        '''\n",
        "        1. Compute dLdx.\n",
        "        2. Return dLdx\n",
        "        '''\n",
        "        return (self.X > 0) * dLdy\n",
        "\n",
        "    def step(self, learning_rate):\n",
        "        pass\n",
        "\n",
        "\n",
        "class ELU:\n",
        "    '''\n",
        "    ELU(x) = x, x > 0; a*(e^x - 1), x <= 0\n",
        "    '''\n",
        "\n",
        "    def __init__(self, a=1):\n",
        "        self.a = a\n",
        "\n",
        "    def forward(self, X):\n",
        "        '''\n",
        "        Passes objects through this layer.\n",
        "        X is np.array of size (N, d)\n",
        "        '''\n",
        "        self.X = X\n",
        "        return X * (X > 0) + self.a * (np.exp(X) - 1) * (X <= 0)\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        '''\n",
        "        1. Compute dLdx.\n",
        "        2. Return dLdx\n",
        "        '''\n",
        "        X = self.X\n",
        "        dydX = (X > 0) + self.a * np.exp(X) * (X <= 0)\n",
        "        return dLdy*dydX\n",
        "\n",
        "    def step(self, learning_rate):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Tanh:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        '''\n",
        "        Passes objects through this layer.\n",
        "        X is np.array of size (N, d)\n",
        "        '''\n",
        "        exp_pos=np.exp(X)\n",
        "        exp_neg = np.exp(-X)\n",
        "        self.tanh_x = (exp_pos-exp_neg)/(exp_pos+exp_neg)\n",
        "        return self.tanh_x\n",
        "\n",
        "    def backward(self, dLdy):\n",
        "        '''\n",
        "        1. Compute dLdx.\n",
        "        2. Return dLdx\n",
        "        '''\n",
        "        return (1-(self.tanh_x)**2)*dLdy\n",
        "\n",
        "    def step(self, learning_rate):\n",
        "        pass\n",
        "\n",
        "class Noise():\n",
        "     def __init__(self, mean, stddev):\n",
        "         self.mean = mean\n",
        "         self.stddev = stddev\n",
        "     def __call__(self, tensor):\n",
        "         noise = torch.zeros_like(tensor).normal_(self.mean, self.stddev)\n",
        "         return tensor.add_(noise)\n",
        "     def __repr__(self):\n",
        "         repr = f\"{self.__class__.__name__}(mean={self.mean},stddev={self.stddev})\"\n",
        "         return repr\n",
        "\n",
        "class Rotation():\n",
        "\n",
        "     def __init__(self, angle_range=(-15, 15)):\n",
        "         self.angle_range  = angle_range\n",
        "     def __call__(self, tensor):\n",
        "         angle = np.random.uniform(self.angle_range[0], self.angle_range[1])\n",
        "         return F.rotate(tensor, angle)\n",
        "     def __repr__(self):\n",
        "         repr = f\"{self.__class__.__name__}(angle_range={self.angle_range})\"\n",
        "         return repr\n",
        "\n",
        "\n",
        "class Shift():\n",
        "\n",
        "    def __init__(self, shift_range=(-0.1, 0.1)):\n",
        "        self.shift_range = shift_range\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        shift_x = np.random.uniform(self.shift_range[0], self.shift_range[1])\n",
        "        shift_y = np.random.uniform(self.shift_range[0], self.shift_range[1])\n",
        "        return F.affine(tensor, angle=0, translate=(shift_x, shift_y), scale=1.0, shear=0)\n",
        "    def __repr__(self):\n",
        "        repr = f\"{self.__class__.__name__}(shift_range={self.shift_range})\"\n",
        "        return repr\n",
        "\n",
        "\n",
        "def train(network, epochs, learning_rate, verbose=True, loss=None):\n",
        "    loss = loss or NLLLoss()\n",
        "    train_loss_epochs = []\n",
        "    test_loss_epochs = []\n",
        "    train_accuracy_epochs = []\n",
        "    test_accuracy_epochs = []\n",
        "    try:\n",
        "        for epoch in range(epochs):\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "            for X, y in train_loader:\n",
        "                X = X.view(X.shape[0], -1).numpy()\n",
        "                y = y.numpy()\n",
        "                prediction = network.forward(X)\n",
        "                loss_batch = loss.forward(prediction, y)\n",
        "                losses.append(loss_batch)\n",
        "                dLdx = loss.backward()\n",
        "                network.backward(dLdx)\n",
        "                network.step(learning_rate)\n",
        "                accuracies.append((np.argmax(prediction, 1) == y).mean())\n",
        "            train_loss_epochs.append(np.mean(losses))\n",
        "            train_accuracy_epochs.append(np.mean(accuracies))\n",
        "\n",
        "            losses = []\n",
        "            accuracies = []\n",
        "            for X, y in test_loader:\n",
        "                X = X.view(X.shape[0], -1).numpy()\n",
        "                y = y.numpy()\n",
        "                prediction = network.forward(X)\n",
        "                loss_batch = loss.forward(prediction, y)\n",
        "                losses.append(loss_batch)\n",
        "                accuracies.append((np.argmax(prediction, 1) == y).mean())\n",
        "            test_loss_epochs.append(np.mean(losses))\n",
        "            test_accuracy_epochs.append(np.mean(accuracies))\n",
        "\n",
        "            if verbose:\n",
        "                print(f'Epoch {epoch}: Train Loss: {train_loss_epochs[-1]:.3f}, '\n",
        "                      f'Test Loss: {test_loss_epochs[-1]:.3f}, '\n",
        "                      f'Train Acc: {train_accuracy_epochs[-1]:.3f}, '\n",
        "                      f'Test Acc: {test_accuracy_epochs[-1]:.3f}')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nTraining interrupted.\")\n",
        "\n",
        "    return train_loss_epochs, test_loss_epochs, train_accuracy_epochs, test_accuracy_epochs\n",
        "if __name__ == \"__main__\":\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "    train_dataset = MNIST('.', train=True, download=True, transform=transform)\n",
        "    test_dataset = MNIST('.', train=False, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    network = NeuralNetwork([\n",
        "        Linear(784, 100), Tanh(),\n",
        "        Linear(100, 100), Tanh(),\n",
        "        Linear(100, 10)\n",
        "    ])\n",
        "    loss = NLLLoss()\n",
        "\n",
        "    tr_loss, ts_loss, tr_acc, ts_acc = train(network, 20, 0.01)\n",
        "\n",
        "    print(f\"\\nFinal Results (Tanh, no augmentations):\")\n",
        "    print(f\"Train Accuracy: {tr_acc[-1]:.3f}, Test Accuracy: {ts_acc[-1]:.3f}\")\n",
        "    print(f\"Train Loss: {tr_loss[-1]:.3f}, Test Loss: {ts_loss[-1]:.3f}\")\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(tr_loss, label='Train Loss', linewidth=2)\n",
        "    plt.plot(ts_loss, label='Test Loss', linewidth=2)\n",
        "    plt.title(\"Loss over Epochs\", fontsize=16)\n",
        "    plt.xlabel('Epochs', fontsize=14)\n",
        "    plt.ylabel('Loss', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(tr_acc, label='Train Accuracy', linewidth=2)\n",
        "    plt.plot(ts_acc, label='Test Accuracy', linewidth=2)\n",
        "    plt.title(\"Accuracy over Epochs\", fontsize=16)\n",
        "    plt.xlabel('Epochs', fontsize=14)\n",
        "    plt.ylabel('Accuracy', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_plots.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Преобразования с аугментациями\n",
        "    transform_rotate = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        Rotation()\n",
        "    ])\n",
        "\n",
        "    transform_shift = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        Shift()\n",
        "    ])\n",
        "\n",
        "    transform_noise = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        Noise(mean=0.0, stddev=0.1)\n",
        "    ])\n",
        "\n",
        "    transform_all = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        Rotation(),\n",
        "        Shift(),\n",
        "        Noise(mean=0.0, stddev=0.1)\n",
        "    ])\n",
        "\n",
        "    # Загрузчики\n",
        "    train_dataset_rotate = MNIST('.', train=True, download=True, transform=transform_rotate)\n",
        "    train_dataset_shift = MNIST('.', train=True, download=True, transform=transform_shift)\n",
        "    train_dataset_noise = MNIST('.', train=True, download=True, transform=transform_noise)\n",
        "    train_dataset_all = MNIST('.', train=True, download=True, transform=transform_all)\n",
        "\n",
        "    train_loader_rotate = DataLoader(train_dataset_rotate, batch_size=32, shuffle=True)\n",
        "    train_loader_shift = DataLoader(train_dataset_shift, batch_size=32, shuffle=True)\n",
        "    train_loader_noise = DataLoader(train_dataset_noise, batch_size=32, shuffle=True)\n",
        "    train_loader_all = DataLoader(train_dataset_all, batch_size=32, shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "t7L7kik55Wz4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def create_network():\n",
        "        return NeuralNetwork([\n",
        "            Linear(784, 100), ReLU(),\n",
        "            Linear(100, 100), ReLU(),\n",
        "            Linear(100, 10)\n",
        "        ])\n",
        "\n",
        "    learning_rate = 0.01\n",
        "    epochs = 20\n",
        "    # Обучение с разными аугментациями\n",
        "    print(\"Обучение без аугментаций\")\n",
        "    net_basic = create_network()\n",
        "    _, ts_loss_basic, _, ts_acc_basic = train(net_basic, epochs, learning_rate, verbose=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koR_cMpC5rHH",
        "outputId": "8faceb36-2d7e-46ae-df8e-93316fdde1bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение без аугментаций\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение с разными аугментациями\n",
        "print(\"Обучение без аугментаций\")\n",
        "net_basic = create_network()\n",
        "_, ts_loss_basic, _, ts_acc_basic = train(net_basic, epochs, learning_rate, verbose=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdyVjEEe5vYQ",
        "outputId": "6594b393-3658-43c2-8ada-f53b701b7a60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение без аугментаций\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Обучение с вращениями\")\n",
        "net_rotate = create_network()\n",
        "_, ts_loss_rotate, _, ts_acc_rotate = train(net_rotate, epochs, learning_rate, verbose=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiLdrt1x5xoa",
        "outputId": "3316e249-09d9-4399-d4be-e83396629b21"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение с вращениями\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Обучение со сдвигами\")\n",
        "net_shift = create_network()\n",
        "_, ts_loss_shift, _, ts_acc_shift = train(net_shift, epochs, learning_rate, verbose=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtj_LU8u57lB",
        "outputId": "1c4ee0cb-49e5-46da-961e-0a00341e5748"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение со сдвигами\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Обучение с шумом\")\n",
        "net_noise = create_network()\n",
        "_, ts_loss_noise, _, ts_acc_noise = train(net_noise, epochs, learning_rate, verbose=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEmIFb6n6Ki2",
        "outputId": "707e45a6-49e7-4c82-ec31-ac2ff48ea97d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение с шумом\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Обучение со всеми аугментациями\")\n",
        "net_all = create_network()\n",
        "_, ts_loss_all, _, ts_acc_all = train(net_all, epochs, learning_rate, verbose=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J499OEc56UXO",
        "outputId": "536f818d-285b-49f4-9a1e-620832a66bc4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение со всеми аугментациями\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# График Test Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Test Loss over Epochs', fontsize=16)\n",
        "plt.plot(ts_loss_basic, label='No Aug', linewidth=2, marker='o')\n",
        "plt.plot(ts_loss_rotate, label='Rotation', linewidth=2, marker='s')\n",
        "plt.plot(ts_loss_shift, label='Shift', linewidth=2, marker='^')\n",
        "plt.plot(ts_loss_noise, label='Noise', linewidth=2, marker='D')\n",
        "plt.plot(ts_loss_all, label='All', linewidth=2, marker='x', linestyle='--')\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# График Test Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Test Accuracy over Epochs', fontsize=16)\n",
        "plt.plot(ts_acc_basic, label='No Aug', linewidth=2, marker='o')\n",
        "plt.plot(ts_acc_rotate, label='Rotation', linewidth=2, marker='s')\n",
        "plt.plot(ts_acc_shift, label='Shift', linewidth=2, marker='^')\n",
        "plt.plot(ts_acc_noise, label='Noise', linewidth=2, marker='D')\n",
        "plt.plot(ts_acc_all, label='All', linewidth=2, marker='x', linestyle='--')\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"augmentation_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7tg2JASd6dnK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Без аугментаций:      {ts_acc_basic[-1]:.4f}\")\n",
        "print(f\"Только вращения:      {ts_acc_rotate[-1]:.4f}\")\n",
        "print(f\"Только сдвиги:        {ts_acc_shift[-1]:.4f}\")\n",
        "print(f\"Только шум:           {ts_acc_noise[-1]:.4f}\")\n",
        "print(f\"Все аугментации:      {ts_acc_all[-1]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0rKg_a56qFz",
        "outputId": "6b0997e8-6ab5-4263-ae9d-8c9bfc14d6ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Без аугментаций:      0.9742\n",
            "Только вращения:      0.9734\n",
            "Только сдвиги:        0.9743\n",
            "Только шум:           0.9774\n",
            "Все аугментации:      0.9740\n"
          ]
        }
      ]
    }
  ]
}